{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8b59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    def __init__(self):\n",
    "        self.dataset = 'ml-100k'\n",
    "        self.epoch = 50\n",
    "        self.worker = 8\n",
    "        self.verbose = 2\n",
    "        self.group = 10\n",
    "        self.layer = [64, 32]\n",
    "        self.learn = 'retrain'\n",
    "        self.deltype = 'random'\n",
    "        self.delper = 5\n",
    "        self.model = 'wmf'\n",
    "\n",
    "args = args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "793ced96",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'ml-100k'\n",
    "args.learn = 'retrain'\n",
    "args.del_type = 'random'\n",
    "args.del_per = 5\n",
    "args.model = 'wmf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4aa9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import numpy as np\n",
    "import torch    \n",
    "import pandas as pd\n",
    "from utils import seed_all, baseTrain, baseTest\n",
    "from utils import WMF, DMF, GMF, NMF, BPR, hit, ndcg\n",
    "from read import RatingData, PairData\n",
    "from read import loadData, readRating_full, readRating_group\n",
    "from config import InsParam, Instance\n",
    "from scratch import Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8e2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomInstance(Instance):\n",
    "    def __init__(self, param, custom_param=None):\n",
    "        super().__init__(param)\n",
    "        self.custom_param = custom_param\n",
    "        \n",
    "    def only_test(self, path=''):\n",
    "        self.train_rating, self.test_rating, self.active_rating, self.inactive_rating = self.read()\n",
    "        if self.param.model in ['wmf', 'dmf', 'gmf', 'nmf']:\n",
    "            self.train_data = loadData(RatingData(self.train_rating), self.param.batch,\n",
    "                                      self.param.n_worker,\n",
    "                                      True)\n",
    "\n",
    "        elif self.param.model in ['bpr', 'lightgcn']:\n",
    "            self.train_data = loadData(PairData(self.train_rating, self.param.pos_data), self.param.batch,\n",
    "                                      self.param.n_worker,\n",
    "                                      True)\n",
    "\n",
    "            self.test_data = loadData(RatingData(self.test_rating), len(self.test_rating[0]), self.param.n_worker, False)\n",
    "            self.active_test_data = loadData(RatingData(self.active_rating), len(self.active_rating[0]), self.param.n_worker,\n",
    "                                        False)\n",
    "            self.inactive_test_data = loadData(RatingData(self.inactive_rating), len(self.inactive_rating[0]), self.param.n_worker,\n",
    "                                          False)\n",
    "\n",
    "        self.scrate = Scratch(self.param, self.param.model)\n",
    "        \n",
    "\n",
    "    def get_model(self, path=''):\n",
    "        seed_all(self.scrate.seed)\n",
    "        if self.scrate.model_type == 'wmf':\n",
    "            model = WMF(self.scrate.n_user, self.scrate.n_item, self.scrate.k).to(self.scrate.device)\n",
    "        elif self.scrate.model_type == 'bpr':\n",
    "            model = BPR(self.scrate.n_user, self.scrate.n_item, self.scrate.k).to(self.scrate.device)\n",
    "        elif self.scrate.model_type == 'gmf':\n",
    "            model = GMF(self.scrate.n_user, self.scrate.n_item, self.scrate.k).to(self.scrate.device)\n",
    "        elif self.scrate.model_type == 'nmf':\n",
    "            model = NMF(self.scrate.n_user, self.scrate.n_item, self.scrate.k, self.scrate.layers).to(self.scrate.device)\n",
    "        elif self.scrate.model_type == 'dmf':\n",
    "            model = DMF(self.scrate.n_user, self.scrate.n_item, self.scrate.k, self.scrate.layers).to(self.scrate.device)\n",
    "            \n",
    "        model.load_state_dict(torch.load(path))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "param = InsParam(args.dataset, args.model, args.epoch, args.worker, args.layer, args.group, args.del_per, args.learn, args.del_type)\n",
    "ins = CustomInstance(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5acd97ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[885, 98, 46, 434, 757, 21, 851, 881, 140, 103, 88, 777, 380, 363, 316, 640, 276, 189, 175, 25, 798, 784, 511, 888, 522, 580, 458, 871, 927, 461, 531, 919, 258, 586, 822, 145, 324, 204, 561, 393, 486, 456, 814, 781, 59, 768, 438]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1139949/2315595474.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    }
   ],
   "source": [
    "ins.only_test()\n",
    "model = ins.get_model(path='../model_params/retrain/wmf_ml-100k_random_0/model.pth')\n",
    "retrain_model = ins.get_model(path='../model_params/retrain/wmf_ml-100k_random_5/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31fdb9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WMF(\n",
       "  (user_mat): Embedding(943, 32)\n",
       "  (item_mat): Embedding(1349, 32)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "retrain_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b872388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5368, -0.3249,  0.3447,  0.3734, -0.3478, -0.1079,  0.3983, -0.3578,\n",
      "        -0.1621, -0.5153,  0.2502,  0.4899,  0.2659, -0.5222,  0.7066, -0.2293,\n",
      "        -0.9415,  0.0398,  0.9333, -0.2786,  0.6326,  0.4908, -0.6176, -0.3008,\n",
      "         0.1051,  0.2242,  0.3318, -0.0406, -0.9538, -0.4640,  0.3426,  0.4195],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 4.0978e-03, -5.0318e-03, -2.0012e-03,  1.6957e-02,  5.7419e-03,\n",
      "        -1.1403e-02,  4.3032e-03, -6.8148e-03,  2.0320e-03,  7.0683e-03,\n",
      "        -2.0675e-04,  4.9379e-03,  4.5500e-03, -1.2044e-02,  5.2639e-03,\n",
      "         8.8330e-05, -5.6867e-03,  1.4124e-02, -9.9349e-03,  4.1977e-04,\n",
      "        -2.8493e-03,  9.4761e-03,  1.3664e-02,  1.2062e-03,  4.5981e-03,\n",
      "        -1.6551e-02, -7.8634e-03, -1.4990e-02, -4.9395e-03, -1.6675e-02,\n",
      "        -6.6674e-03,  4.0870e-03], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "unlearn_list = [885, 98, 46, 434, 757, 21, 851, 881, 140, 103, 88, 777, 380, 363, 316, 640, 276, 189, 175, 25, 798, 784, 511, 888, 522, 580, 458, 871, 927, 461, 531, 919, 258, 586, 822, 145, 324, 204, 561, 393, 486, 456, 814, 781, 59, 768, 438]\n",
    "print(model.user_mat.weight[unlearn_list[0]])\n",
    "print(retrain_model.user_mat.weight[unlearn_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e9100d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({\n",
    "    \"uid\": ins.train_rating[0],\n",
    "    \"iid\": ins.train_rating[1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a641c525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([943, 1349])\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "interaction_matrix = torch.zeros(ins.param.n_user, ins.param.n_item, device=device)\n",
    "    \n",
    "user_indices = train_df['uid'].values\n",
    "item_indices = train_df['iid'].values\n",
    "    \n",
    "if user_indices.min() == 1:\n",
    "    user_indices = user_indices - 1\n",
    "if item_indices.min() == 1:\n",
    "    item_indices = item_indices - 1\n",
    "    \n",
    "interaction_matrix[user_indices, item_indices] = 1\n",
    "interaction_matrix\n",
    "\n",
    "print(interaction_matrix.size())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a0a2be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = torch.matmul(model.user_mat.weight, model.item_mat.weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36feb3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_interaction_matrix = interaction_matrix\n",
    "delete_users = [885, 98, 46, 434, 757, 21, 851, 881, 140, 103, 88, 777, 380, 363, 316, 640, 276, 189, 175, 25, 798, 784, 511, 888, 522, 580, 458, 871, 927, 461, 531, 919, 258, 586, 822, 145, 324, 204, 561, 393, 486, 456, 814, 781, 59, 768, 438]\n",
    "mask = torch.ones(len(original_interaction_matrix), dtype=torch.bool)\n",
    "mask[delete_users] = False\n",
    "ideal_interaction_matrix = original_interaction_matrix[mask]\n",
    "predict_prob = torch.sigmoid(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be12a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_based_unlearning(original_interaction_matrix, ideal_interaction_matrix, \n",
    "                        predict_prob, delete_users, device='cuda', \n",
    "                        alpha=0.5, beta=0.3, rank_ratio=0.8):\n",
    "    \"\"\"\n",
    "    SVD 기반 언러닝 구현\n",
    "    \n",
    "    Args:\n",
    "        original_interaction_matrix: 원본 상호작용 행렬 (num_users, num_items)\n",
    "        ideal_interaction_matrix: 이상적 상호작용 행렬 (num_users-deleted, num_items)\n",
    "        predict_prob: 모델 예측 확률 (num_users, num_items)\n",
    "        delete_users: 삭제할 사용자 인덱스 리스트\n",
    "        alpha: 아이템 공간 보정 가중치\n",
    "        beta: 특이값 보정 가중치\n",
    "        rank_ratio: 사용할 rank 비율\n",
    "    \n",
    "    Returns:\n",
    "        corrected_predictions: 보정된 예측 행렬\n",
    "        unlearning_metrics: 언러닝 품질 지표\n",
    "    \"\"\"\n",
    "    \n",
    "    # GPU/CPU 설정\n",
    "    device = original_interaction_matrix.device\n",
    "    \n",
    "    print(f\"Original matrix shape: {original_interaction_matrix.shape}\")\n",
    "    print(f\"Ideal matrix shape: {ideal_interaction_matrix.shape}\")\n",
    "    print(f\"Prediction matrix shape: {predict_prob.shape}\")\n",
    "    print(f\"Number of users to delete: {len(delete_users)}\")\n",
    "    \n",
    "    # 1. 각 행렬을 numpy로 변환하여 SVD 수행\n",
    "    R_original = original_interaction_matrix.cpu().float().numpy()\n",
    "    R_ideal = ideal_interaction_matrix.cpu().float().numpy()\n",
    "    R_pred = predict_prob.detach().cpu().float().numpy()\n",
    "    \n",
    "    # 2. SVD 분해\n",
    "    print(\"Performing SVD decomposition...\")\n",
    "    \n",
    "    # Original matrix SVD\n",
    "    U1, S1, V1 = np.linalg.svd(R_original, full_matrices=False)\n",
    "    \n",
    "    # Ideal matrix SVD\n",
    "    U2, S2, V2 = np.linalg.svd(R_ideal, full_matrices=False)\n",
    "    \n",
    "    # Prediction matrix SVD\n",
    "    U3, S3, V3 = np.linalg.svd(R_pred, full_matrices=False)\n",
    "    \n",
    "    print(f\"SVD shapes - Original: U1{U1.shape}, S1{S1.shape}, V1{V1.shape}\")\n",
    "    print(f\"SVD shapes - Ideal: U2{U2.shape}, S2{S2.shape}, V2{V2.shape}\")\n",
    "    print(f\"SVD shapes - Prediction: U3{U3.shape}, S3{S3.shape}, V3{V3.shape}\")\n",
    "    \n",
    "    # 3. 사용할 rank 결정\n",
    "    min_rank = min(len(S1), len(S2), len(S3))\n",
    "    target_rank = int(min_rank * rank_ratio)\n",
    "    \n",
    "    print(f\"Using rank: {target_rank} (from min_rank: {min_rank})\")\n",
    "    \n",
    "    # 4. 차원 축소 및 정렬\n",
    "    V1_truncated = V1[:target_rank, :]\n",
    "    V2_truncated = V2[:target_rank, :]\n",
    "    V3_truncated = V3[:target_rank, :]\n",
    "    \n",
    "    S1_truncated = S1[:target_rank]\n",
    "    S2_truncated = S2[:target_rank]\n",
    "    S3_truncated = S3[:target_rank]\n",
    "    \n",
    "    # 5. Procrustes analysis로 방향 정렬\n",
    "    try:\n",
    "        R_align, _ = orthogonal_procrustes(V2_truncated.T, V1_truncated.T)\n",
    "        V2_aligned = (V2_truncated.T @ R_align).T\n",
    "    except:\n",
    "        print(\"Procrustes alignment failed, using direct alignment\")\n",
    "        V2_aligned = V2_truncated\n",
    "    \n",
    "    # 6. 차이 계산\n",
    "    Delta_V = V2_aligned - V1_truncated\n",
    "    Delta_S = S2_truncated - S1_truncated\n",
    "    \n",
    "    print(f\"Delta_V norm: {np.linalg.norm(Delta_V):.6f}\")\n",
    "    print(f\"Delta_S norm: {np.linalg.norm(Delta_S):.6f}\")\n",
    "    \n",
    "    # 7. 예측 행렬 보정\n",
    "    V3_corrected = V3_truncated + alpha * Delta_V\n",
    "    S3_corrected = S3_truncated + beta * Delta_S\n",
    "    \n",
    "    # 특이값 양수 유지\n",
    "    S3_corrected = np.maximum(S3_corrected, 0.01 * S3_truncated)\n",
    "    \n",
    "    # 8. 사용자 공간 조정\n",
    "    U3_corrected = U3[:, :target_rank].copy()\n",
    "    \n",
    "    # 삭제된 사용자들의 임베딩을 0으로 설정\n",
    "    U3_corrected[delete_users, :] = 0\n",
    "    \n",
    "    print(f\"Zeroed embeddings for {len(delete_users)} users\")\n",
    "    \n",
    "    # 9. 보정된 예측 행렬 재구성\n",
    "    R_corrected = U3_corrected @ np.diag(S3_corrected) @ V3_corrected\n",
    "    \n",
    "    # 10. PyTorch tensor로 변환\n",
    "    corrected_predictions = torch.tensor(R_corrected, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # 11. 확률 범위로 클리핑 (sigmoid 출력이므로 0-1 범위)\n",
    "    corrected_predictions = torch.clamp(corrected_predictions, 0.0, 1.0)\n",
    "    \n",
    "    # 12. 언러닝 품질 평가\n",
    "    \n",
    "    return corrected_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ed73628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix shape: torch.Size([943, 1349])\n",
      "Ideal matrix shape: torch.Size([896, 1349])\n",
      "Prediction matrix shape: torch.Size([943, 1349])\n",
      "Number of users to delete: 47\n",
      "Performing SVD decomposition...\n",
      "SVD shapes - Original: U1(943, 943), S1(943,), V1(943, 1349)\n",
      "SVD shapes - Ideal: U2(896, 896), S2(896,), V2(896, 1349)\n",
      "SVD shapes - Prediction: U3(943, 943), S3(943,), V3(943, 1349)\n",
      "Using rank: 896 (from min_rank: 896)\n",
      "Delta_V norm: 0.000031\n",
      "Delta_S norm: 0.000000\n",
      "Zeroed embeddings for 47 users\n"
     ]
    }
   ],
   "source": [
    "unlearned_matrix = svd_based_unlearning(original_interaction_matrix, ideal_interaction_matrix,\n",
    "                     predict_prob, delete_users, 'cuda',\n",
    "                    0.5, 0.3, 1.0\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "596aadbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([943, 1349])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlearned_matrix.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "952e821e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1728, 0.6800, 0.0808,  ..., 0.0069, 0.0023, 0.9540], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_prob[delete_users[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "293485d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlearned_matrix[delete_users[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88ea5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readRating_full(train_dir, test_dir, del_type='random', del_per=5):\n",
    "    train_ratings = pd.read_csv(train_dir, sep=',')\n",
    "    test_ratings = pd.read_csv(test_dir, sep=',')\n",
    "\n",
    "    del_user = delete_users\n",
    "    train_ratings = train_ratings[~train_ratings['uid'].isin(del_user)].reset_index(drop=True)\n",
    "    test_ratings = test_ratings[~test_ratings['uid'].isin(del_user)].reset_index(drop=True)\n",
    "    # active and inactive\n",
    "    user_counts = train_ratings['uid'].value_counts()\n",
    "    num_active_users = int(len(user_counts) * 5 / 100)\n",
    "\n",
    "    active_users = user_counts.index[:num_active_users].tolist()\n",
    "    inactive_users = user_counts.index[num_active_users:].tolist()\n",
    "    # test set\n",
    "    active_ratings = test_ratings[test_ratings['uid'].isin(active_users)].reset_index(drop=True)\n",
    "    inactive_ratings = test_ratings[test_ratings['uid'].isin(inactive_users)].reset_index(drop=True)\n",
    "\n",
    "    train_rating_lists = [train_ratings['uid'], train_ratings['iid'], train_ratings['val']]\n",
    "    test_rating_lists = [test_ratings['uid'], test_ratings['iid'], test_ratings['val']]\n",
    "\n",
    "    active_ratings = [active_ratings['uid'], active_ratings['iid'], active_ratings['val']]\n",
    "    inactive_ratings = [inactive_ratings['uid'], inactive_ratings['iid'], inactive_ratings['val']]\n",
    "\n",
    "    return train_rating_lists, test_rating_lists, active_ratings, inactive_ratings\n",
    "_, test_rating, _, _ = readRating_full(ins.param.train_dir, ins.param.test_dir, del_type='random', del_per=5)\n",
    "origin_test_data = loadData(RatingData(ins.test_rating), len(ins.test_rating[0]), ins.param.n_worker, False)\n",
    "unlearned_test_data = loadData(RatingData(test_rating), len(test_rating[0]), ins.param.n_worker, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11d8a684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3077901046343992, 0.31673471658559144)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pos_dict = np.load(ins.param.pos_data, allow_pickle=True).item()\n",
    "print(baseTest(unlearned_test_data, retrain_model, 'point-wise', device, 2, pos_dict, unlearned_matrix.size(1), 20, None, None))\n",
    "# print(baseTest2(unlearned_test_data, unlearned_matrix, 'point-wise', device, 2, pos_dict, unlearned_matrix.size(1), 20, None, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b0d311",
   "metadata": {},
   "source": [
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c3ee04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseTest2(dataloader, matrix, loss_fn, device, verbose, pos_dict, \n",
    "             n_items, top_k=20, user_mapping=None,\n",
    "             pos_mapping=None):\n",
    "\n",
    "    full_items = [i for i in range(n_items)]\n",
    "\n",
    "    HR = []\n",
    "    NDCG = []\n",
    "\n",
    "    for user, item, rating in dataloader:\n",
    "        all_users = user.unique()\n",
    "        all_users = all_users.to(device)\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "\n",
    "        for uid in all_users:\n",
    "            user_id = uid.item()\n",
    "            user_indices = torch.where(user == uid)\n",
    "            gt_items = item[user_indices].cpu().numpy().tolist()\n",
    "\n",
    "            neg_items = list(set(full_items) - set(pos_dict[user_id]))\n",
    "\n",
    "            new_user = torch.tensor([user_id] * len(neg_items), dtype=torch.long).to(device)\n",
    "            new_item = torch.tensor(neg_items, dtype=torch.long).to(device)\n",
    "            \n",
    "            \n",
    "            predictions = matrix[new_user, new_item]            \n",
    "            # predictions = model(new_user, new_item)\n",
    "            _, indices = torch.topk(predictions, top_k)\n",
    "            recommends = torch.take(new_item, indices).cpu().numpy().tolist()\n",
    "\n",
    "            HR.append(hit(gt_items, recommends))\n",
    "            NDCG.append(ndcg(gt_items, recommends))\n",
    "\n",
    "    return np.mean(NDCG), np.mean(HR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d58b904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3110820619083067, 0.3213303344050097)\n"
     ]
    }
   ],
   "source": [
    "print(baseTest2(unlearned_test_data, unlearned_matrix, 'point-wise', device, 2, pos_dict, unlearned_matrix.size(1), 20, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5925cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_user, retrain_item = retrain_model.user_mat.weight, retrain_model.item_mat.weight\n",
    "retrain_predict_matrix = torch.sigmoid(retrain_user @ retrain_item.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b75a82ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([943, 1349])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrain_predict_matrix.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65773238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cure4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
